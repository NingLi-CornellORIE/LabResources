{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling from symmetric Dirichlet distribution priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equations\n",
    "\n",
    "This Markdown cell has **equations**, written using [*LaTeX*](http://www.latex-project.org/) syntax and rendered in the browser using [*MathJax*](http://www.mathjax.org/) (which [the Cornell Library helped develop!](http://news.library.cornell.edu/news/110104/mathjax)).\n",
    "\n",
    "For help with LaTeX/MathJax math syntax, see:\n",
    "* [Math Examples — Jupyter Notebook documentation](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Typesetting%20Equations.html)\n",
    "* [A Primer on Using LaTeX in Jupyter Notebooks | Democratizing Data](http://data-blog.udacity.com/posts/2016/10/latex-primer/) — A brief blog post introducing essential notation (Bayes's theorem is an example!)\n",
    "* A short [MathJax tutorial](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) at the StackExchange MathematicsMeta site\n",
    "* A two-page [Quick guide to LaTeX](http://divisbyzero.com/2011/08/17/a-quick-guide-to-latex/) (PDF; useful mainly just for the list of symbols)\n",
    "* A [gentle intro the basics at FluidMind.org](http://fluidmind.org/articles/typesetting-equations/) (just go through the first three sections, through \"Placing Equations on Web Pages\")\n",
    "* The [*AMS Short Math Guide for LaTeX*](https://ctan.org/tex-archive/info/short-math-guide?lang=en) (PDF file); note that not everything described here is implemented in MathJax\n",
    "* The Harvard math department hosts [An introduction to Using TeX](http://www.math.harvard.edu/texman/); for MathJax use, the \"Commands for Math Mode\" is most relevant\n",
    "\n",
    "Note that equation support is an *extension* to basic Markdown, and not fully standardized.  If you are using a standalone Markdown editor/previewer, or a different browser-based Markdown editor (such as [StackEdit](https://stackedit.io/)), be aware that there are different conventions for how to set off inline and displayed equations in extended Markdown:\n",
    "* [Survey of syntaxes for math in markdown](https://github.com/cben/mathdown/wiki/math-in-markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equation examples\n",
    "\n",
    "Here is *Bayes's theorem* for a posterior distribution over a set of hypotheses $\\{H_i\\}$ based on observed data $D$:\n",
    "$$\n",
    "p(H_i|D) = \\frac{p(H_i) p(D|H_i)}{p(D)} \\qquad ||~\\mathcal{C}.\n",
    "$$\n",
    "And, of course, the all-important *LTP*, where $\\{B_j\\}$ is a *suite* (i.e., a mutually exclusive, exhaustive set of alternatives):\n",
    "$$\n",
    "p(H_i) = \\sum_j p(H_i,B_j) = \\sum_j p(B_j) p(H_i|B_j) \\qquad ||~\\mathcal{C}.\n",
    "$$\n",
    "And since it's so important, let's write the LTP with alignment (using the LaTeX *align* environment):\n",
    "\\begin{align}\n",
    "p(H_i)\n",
    "  &= \\sum_j p(H_i,B_j)\\\\\n",
    "  &= \\sum_j p(B_j) p(H_i|B_j) \\qquad ||~\\mathcal{C}.\n",
    "\\end{align}\n",
    "\n",
    "Finally, here's the *generalized beta integral*, from the lecture on categorical/multinomial inference (I'll use a *split* environment, so I can break the long equation):\n",
    "\\begin{split}\n",
    "\\int_0^\\infty d\\alpha_1 \\cdots \\int_0^\\infty d\\alpha_K\\;\n",
    "  & % ampersand indicates align here\n",
    "  \\alpha_1^{\\kappa_1-1}\\cdots\\alpha_K^{\\kappa_K-1} \\delta\\left(a-\\sum_k\\alpha_k\\right)\\\\  % split!\n",
    "  &= \\frac{\\Gamma(\\kappa_1)\\cdots\\Gamma(\\kappa_K)}{\\Gamma(\\kappa_0)}\\; a^{\\kappa_0-1}\n",
    "\\end{split}\n",
    "where $\\kappa_0 = \\sum_{k=1}^K \\kappa_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables\n",
    "\n",
    "This Markdown cell has a table.  To automatically generate nice-looking Markdown table markup, I used\n",
    "[TablesGenerator](http://www.tablesgenerator.com/markdown_tables).  This table could hold ingredients for calculating the posterior PMF for the Monty Hall problem:\n",
    "\n",
    "| Hypothesis | Prior | Likelihood | Prior $\\times$ Likelihood | Posterior |\n",
    "|------------|-------|------------|---------------------------|-----------|\n",
    "| A          |       |            |                           |           |\n",
    "| B          |       |            |                           |           |\n",
    "| C          |       |            |                           |           |\n",
    "| Sum        | 1     | NA         |                           |     1     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Dirichlet distributions\n",
    "\n",
    "One compelling criterion for a categorical prior that is uninformative about the categorical PMF is that the prior not express any preference for some categories over others.  This requires that the prior be *symmetric* with respect to the $\\alpha_k$ category probability parameters.\n",
    "\n",
    "The Dirichlet distribution is a PDF for the $\\alpha_k$ parameters describing a categorical PMF.  It has $K$ concentration parameters, $\\kappa_k$. The Dirichlet PDF is given by\n",
    "$$\n",
    "p(\\alpha_1,\\ldots,\\alpha_K) =\n",
    "  \\frac{\\Gamma(\\kappa_0)}{\\Gamma(\\kappa_1)\\cdots\\Gamma(\\kappa_K)}\\;\n",
    "  \\alpha_1^{\\kappa_1-1}\\cdots\\alpha_K^{\\kappa_K-1}\\;\n",
    "  \\delta\\left(1-\\sum_k\\alpha_k\\right),\n",
    "$$\n",
    "where $\\kappa_0 = \\sum_{k=1}^K \\kappa_k$. \n",
    "\n",
    "A *symmetric* Dirichlet distribution is a Dirichlet distribution with all concentration parameters equal to each other: $\\kappa_i = \\kappa$:\n",
    "$$\n",
    "p(\\alpha_1,\\ldots,\\alpha_K) =\n",
    "  \\frac{\\Gamma(K\\cdot\\kappa)}{[\\Gamma(\\kappa)]^K}\\;\n",
    "  \\alpha_1^{\\kappa-1}\\cdots\\alpha_K^{\\kappa-1}\\;\n",
    "  \\delta\\left(1-\\sum_k\\alpha_k\\right),\n",
    "$$\n",
    "If $\\kappa = 1$, the resulting symmetric Dirichlet PDF is constant—the prior used in Lec06. Here we'll explore this prior, and an alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import *\n",
    "from scipy import *\n",
    "from scipy.stats import dirichlet\n",
    "\n",
    "from shelves import shelves\n",
    "\n",
    "# pyplot.ion() tells Jupyter to make plots in cells, or tells IPython\n",
    "# to make plots in an interactive window.\n",
    "ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SymmetricDirichlet:\n",
    "    \n",
    "    def __init__(self, ncat, kappa):\n",
    "        \"\"\"\n",
    "        Define a symmetric Dirichlet distribution over PMFs with `ncat` categories,\n",
    "        with each category's concentration parameter equal to `kappa`.\n",
    "        \"\"\"\n",
    "        self.ncat = ncat\n",
    "        self.kappa = kappa\n",
    "        self.kappa0 = ncat*kappa\n",
    "        self.kappas = kappa*ones(ncat)\n",
    "        \n",
    "        # Define the Dirichlet by setting all kappas = kappa.\n",
    "        self.distn = dirichlet(self.kappas)\n",
    "\n",
    "    def pdf(self, alphas):\n",
    "        \"\"\"\n",
    "        Compute the PDF for category probabilities given by `alphas`.\n",
    "        \"\"\"\n",
    "        return self.distn.pdf(alphas)\n",
    "\n",
    "    def sample(self, n=1):\n",
    "        \"\"\"\n",
    "        Return `n` samples from a symmetric Dirichlet.\n",
    "        \"\"\"\n",
    "        return self.distn.rvs(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform symmetric Dirichlet priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatsd2 = SymmetricDirichlet(2, 1.)\n",
    "samps = flatsd2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(samples, delta=1.2):\n",
    "    \"\"\"\n",
    "    Make a stack of plots of the PMFs in `samples`, each one offset\n",
    "    vertically by `delta`.\n",
    "    \"\"\"\n",
    "    figure(figsize=(10,7))\n",
    "    dy = 0.  # starting shift\n",
    "    for samp in samples:\n",
    "        shelves(samp, dy=dy)  # imported from shelves.py\n",
    "        axhline(dy, c='k')\n",
    "        dy += delta\n",
    "\n",
    "    xlim(0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatsd5 = SymmetricDirichlet(5, 1.)\n",
    "samps = flatsd5.sample(10)\n",
    "plot_samples(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatsd20 = SymmetricDirichlet(20, 1.)\n",
    "samps = flatsd20.sample(10)\n",
    "plot_samples(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_samples(samps, delta=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand this behavior, recall the single-category marginal implied by a Dirichlet distribution.  E.g., in Lec06, we found that for three categories, the marginal posterior for $\\alpha_1$ when we use a flat prior and see $(n_1, n_2, n_3)$ counts (with $N=n_1+n_2+n_3$) is\n",
    "\\begin{align}\n",
    "p(\\alpha_1|D)\n",
    "  &= \\int d\\alpha_2 \\int d\\alpha_3\\; p(\\alpha_1,\\alpha_2,\\alpha_3|D)\\\\\n",
    "  &\\propto \\alpha_1^{n_1} \\int d\\alpha_2 \\int d\\alpha_3\\; \n",
    "      \\alpha_2^{n_2}\\alpha_3^{n_3}\n",
    "      \\; \\delta\\left[(1-\\alpha_1) - (\\alpha_2 + \\alpha_3)\\right]\\\\\n",
    "  &\\propto \\alpha_1^{n_1} (1-\\alpha_1)^{n_2+n_3}; \\qquad \\mbox{note } n_2+n_3 = N-n_1.\n",
    "\\end{align}\n",
    "What does this imply for a many-category flat prior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-uniform symmetric Dirichlet priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"ac\" for \"aggregation consistent\" - see exercise!\n",
    "acsd5 = SymmetricDirichlet(5, 1./5)\n",
    "samps = acsd5.sample(10)\n",
    "plot_samples(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acsd20 = SymmetricDirichlet(20, 1./20)\n",
    "samps = acsd20.sample(10)\n",
    "plot_samples(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something in between:\n",
    "sd20 = SymmetricDirichlet(20, 1./sqrt(20))\n",
    "samps = sd20.sample(10)\n",
    "plot_samples(samps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
